import os
import json
import re
import hashlib
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from enum import Enum
from typing import List, Optional
from dotenv import load_dotenv
from pydantic import BaseModel, Field, ValidationError
from langchain_openai import ChatOpenAI
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.vectorstores.utils import filter_complex_metadata
from langchain_community.retrievers import TavilySearchAPIRetriever
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter


load_dotenv()

def check_api_keys():
    openai_key = os.getenv("OPENAI_API_KEY")
    tavily_key = os.getenv("TAVILY_API_KEY")
    if not openai_key:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    if not tavily_key:
        print("âŒ TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    print("âœ… API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return True


class IndustryEnum(str, Enum):
    HEALTHCARE = "Healthcare"
    FINANCE = "Finance"
    MARKETING = "Marketing"
    EDUCATION = "Education"
    GAMING = "Gaming"
    MEDIA = "Media"


class FundingStageEnum(str, Enum):
    ANGEL = "Angel"
    PRE_SEED = "Pre-Seed"
    SEED = "Seed"
    SERIES_A = "Series A"


class GenerativeAIStartup(BaseModel):
    startup_name: str = Field(description="Startup company name")
    technology_description: str = Field(description="2-3 line description of main technology and services")
    website: Optional[str] = Field(default="Information not available")
    founded_year: Optional[int] = Field(default=None)
    country: str
    ceo: str = Field(default="Information not available")
    funding_stage: FundingStageEnum
    funding_details: str
    industry: IndustryEnum
    core_technology: str
    source_urls: List[str]


class GenerativeAIStartupList(BaseModel):
    items: List[GenerativeAIStartup]


def extract_ceo_name_only(raw_text: str) -> str:
    if not raw_text or raw_text == "Information not available":
        return "Information not available"
    text = re.sub(r'\([^)]*\)', '', raw_text)
    keywords_to_remove = [
        'CEO', 'Chief Executive Officer', 'Founder', 'Co-Founder', 'Co-founder',
        'President', 'Director', 'Executive', 'Owner', 'Leader',
        'ëŒ€í‘œ', 'ê³µë™ëŒ€í‘œ', 'ì°½ë¦½ì', 'ê³µë™ì°½ë¦½ì', 'ìµœê³ ê²½ì˜ì',
        'founded by', 'established by', 'led by', 'current CEO',
        ':', '-', '|', 'and', '&', 'of', 'at'
    ]
    for keyword in keywords_to_remove:
        text = re.sub(rf'\b{keyword}\b', '', text, flags=re.IGNORECASE)
    if ',' in text:
        text = text.split(',')[0]
    text = re.sub(r'\s+', ' ', text).strip()
    if len(text) > 50 or len(re.findall(r'\d', text)) > 5 or len(text) < 2:
        return "Information not available"
    return text


class GenerativeAIStartupRAG:
    def __init__(self):
        if not check_api_keys():
            raise ValueError("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.0,
            max_tokens=2000,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
        )
        self.structured_llm = self.llm.with_structured_output(GenerativeAIStartupList)

        self.web_search_llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.0,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
        )
        web_search_tool = {"type": "web_search_preview"}
        self.web_search_llm_with_tools = self.web_search_llm.bind_tools([web_search_tool])

        self.embeddings = HuggingFaceBgeEmbeddings(
            model_name="BAAI/bge-base-en-v1.5",
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True},
            query_instruction="Represent this sentence for searching relevant passages: "
        )

        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=150,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
        )

        self.web_retriever = TavilySearchAPIRetriever(
            k=12,
            search_depth="advanced",
            include_generated_answer=True,
            include_raw_content=True,
            include_images=False,
            api_key=os.getenv("TAVILY_API_KEY"),
        )

        self.vector_store = None
        self.vector_retriever = None
        self.query_cache = {}

        self.prompt = ChatPromptTemplate.from_template("""
You are a generative AI startup analysis specialist.

From the provided web search information, identify up to 5 notable generative AI startups that meet ALL criteria below, preferably 3â€“5:
- Uses generative AI as core business
- Has launched or is developing real products/services
- **CRITICAL**: Has received funding at Angel, Pre-Seed, Seed, or Series A stage (NO Series B, C, D or later stages)
- Funding must be between 2015-2025
- **VERY IMPORTANT**: Must have current CEO information available


For EACH startup, extract:
- Company Name (official)
- Technology Description (2-3 sentences)
- Website (official)
- Founded Year
- Country (HQ)
- **CEO: THIS IS CRITICAL - Extract ONLY the current CEO's NAME**
  **IMPORTANT**: Return ONLY the person's name, WITHOUT any titles, roles, or descriptions
  **Examples of CORRECT format:**
    - "John Doe" (not "John Doe (CEO)")
    - "Jane Smith" (not "CEO Jane Smith")
    - "ì´ìŠ¹ìš°" (not "ì´ìŠ¹ìš° ëŒ€í‘œ")
  **What to look for:**
    - "CEO [Name]", "[Name] CEO", "led by [Name]", "current CEO is [Name]"
    - Korean: "ëŒ€í‘œ [Name]", "[Name] ëŒ€í‘œ", "ìµœê³ ê²½ì˜ì [Name]"
  **If multiple CEOs or co-CEOs, list first name only**
- Funding Stage: **MUST BE ONE OF**: Angel, Pre-Seed, Seed, Series A
- Funding Details: Amount raised and key investors
- Industry: **MUST BE ONE OF**: Healthcare, Finance, Marketing, Education, Gaming, Media
- Core Technology: Main generative AI technology being used
- Source URLs (where the info is obtained)


**CRITICAL REQUIREMENTS**:
1. **PRIORITIZE startups where CEO information is clearly available**
2. **CEO field must contain ONLY the person's name - NO titles, NO roles, NO parentheses**
3. Funding Stage MUST be exactly one of: Angel, Pre-Seed, Seed, Series A
4. Industry MUST be exactly one of: Healthcare, Finance, Marketing, Education, Gaming, Media
5. DO NOT include companies that have raised Series B, C, D or beyond


<searched_information>
{context}
</searched_information>


User question: {input}


Return the result in Korean, and produce between 2 and 5 startups (ideally 5) that best fit the criteria.
Focus on startups in early funding stages (Angel to Series A only) **WITH AVAILABLE CEO NAME**.
""")

    def create_vector_db_from_web_search(self, query: str) -> None:
        print("ğŸ” ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        try:
            query_hash = hashlib.md5(query.encode()).hexdigest()
            if query_hash in self.query_cache:
                print("âœ… ìºì‹œëœ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                cached_docs = self.query_cache[query_hash]
                self._build_vector_store(cached_docs)
                return

            print("ğŸ”„ ë³‘ë ¬ ì›¹ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

            with ThreadPoolExecutor(max_workers=2) as executor:
                future_general = executor.submit(self.web_retriever.invoke, query)
                ceo_query = query + " CEO current chief executive officer ëŒ€í‘œ"
                future_ceo = executor.submit(self.web_retriever.invoke, ceo_query)

                web_docs = future_general.result()
                ceo_docs = future_ceo.result()

            seen_urls = set()
            all_docs = []

            for doc in web_docs + ceo_docs:
                url = doc.metadata.get('source', '')
                if url not in seen_urls:
                    seen_urls.add(url)
                    all_docs.append(doc)

            if not all_docs:
                print("âŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            print(f"ğŸ“„ {len(all_docs)}ê°œì˜ ê³ ìœ  ì›¹ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            self.query_cache[query_hash] = all_docs
            self._build_vector_store(all_docs)

        except Exception as e:
            print(f"âŒ ì›¹ ê²€ìƒ‰ ë˜ëŠ” ë²¡í„° DB ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def _build_vector_store(self, docs):
        print("ğŸ§¹ ë³µì¡í•œ ë©”íƒ€ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        filtered_docs = filter_complex_metadata(docs)
        print(f"âœ… {len(filtered_docs)}ê°œì˜ ë¬¸ì„œì—ì„œ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì™„ë£Œ")

        split_docs = self.text_splitter.split_documents(filtered_docs)
        print(f"âœ‚ï¸ ë¬¸ì„œë¥¼ {len(split_docs)}ê°œ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")

        print("ğŸ”„ FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        self.vector_store = FAISS.from_documents(
            documents=split_docs,
            embedding=self.embeddings
        )

        self.vector_retriever = self.vector_store.as_retriever(
            search_type="mmr",
            search_kwargs={
                "k": 15,
                "fetch_k": 40,
                "lambda_mult": 0.7
            }
        )
        print("âœ… FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ!")

    def add_enriched_startups_to_vector_store(self, startups: List[GenerativeAIStartup]) -> None:
        print("\n" + "=" * 60)
        print("ğŸ’¾ ë³´ì™„ëœ ìŠ¤íƒ€íŠ¸ì—… ë°ì´í„°ë¥¼ FAISS ë²¡í„° DBì— ì¶”ê°€ ì¤‘...")
        print("=" * 60)

        if not self.vector_store:
            print("âš ï¸ ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        enriched_docs = []

        for startup in startups:
            enriched_text = f"""
ìŠ¤íƒ€íŠ¸ì—…ëª…: {startup.startup_name}
CEO: {startup.ceo}
ì„¤ë¦½ë…„ë„: {startup.founded_year if startup.founded_year else 'ì •ë³´ ì—†ìŒ'}
êµ­ê°€: {startup.country}
ì›¹ì‚¬ì´íŠ¸: {startup.website}
ì‚°ì—…: {startup.industry.value}
í•µì‹¬ ê¸°ìˆ : {startup.core_technology}
íˆ¬ì ë‹¨ê³„: {startup.funding_stage.value}
íˆ¬ì ì„¸ë¶€ì‚¬í•­: {startup.funding_details}
ê¸°ìˆ  ì„¤ëª…: {startup.technology_description}
"""
            doc = Document(
                page_content=enriched_text,
                metadata={
                    "type": "enriched_startup_data",
                    "startup_name": startup.startup_name,
                    "ceo": startup.ceo,
                    "country": startup.country,
                    "industry": startup.industry.value,
                    "funding_stage": startup.funding_stage.value,
                    "source": "gpt_enriched_data"
                }
            )
            enriched_docs.append(doc)
            print(f"   âœ… {startup.startup_name} ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")

        try:
            print(f"\nğŸ”„ {len(enriched_docs)}ê°œì˜ ë³´ì™„ëœ ë¬¸ì„œë¥¼ ì„ë² ë”© ì¤‘...")
            self.vector_store.add_documents(enriched_docs)
            print(f"âœ… {len(enriched_docs)}ê°œì˜ ë³´ì™„ëœ ìŠ¤íƒ€íŠ¸ì—… ë°ì´í„°ê°€ ë²¡í„° DBì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")

            total_docs = self.vector_store.index.ntotal
            print(f"ğŸ“Š í˜„ì¬ ë²¡í„° DB ì´ ë¬¸ì„œ ìˆ˜: {total_docs}")

        except Exception as e:
            print(f"âŒ ë²¡í„° DB ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")

    def save_vector_store(self, save_path: str = "./faiss_enriched_index") -> None:
        if not self.vector_store:
            print("âš ï¸ ì €ì¥í•  ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        try:
            self.vector_store.save_local(save_path)
            print(f"ğŸ’¾ ë²¡í„° ìŠ¤í† ì–´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")
        except Exception as e:
            print(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    def load_vector_store(self, load_path: str = "./faiss_enriched_index") -> None:
        try:
            self.vector_store = FAISS.load_local(
                load_path, 
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            self.vector_retriever = self.vector_store.as_retriever(
                search_type="mmr",
                search_kwargs={
                    "k": 15,
                    "fetch_k": 40,
                    "lambda_mult": 0.7
                }
            )
            print(f"âœ… ë²¡í„° ìŠ¤í† ì–´ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {load_path}")
        except Exception as e:
            print(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

    def sup_missing_ceo_with_gpt(self, company_name: str) -> str:
        print(f"ğŸ¤– GPT ì›¹ ê²€ìƒ‰ìœ¼ë¡œ {company_name}ì˜ CEO ì´ë¦„ì„ ì°¾ëŠ” ì¤‘...")

        try:
            search_prompt = f"""
You are an AI assistant with web search capabilities. 


**Task:** Find the current CEO of {company_name}


**CRITICAL INSTRUCTION:** Return ONLY the CEO's full name. Do NOT include:
- Titles (CEO, Chief Executive Officer, President, etc.)
- Roles (Founder, Co-Founder, etc.)
- Parentheses or brackets
- Additional descriptions
- Korean titles (ëŒ€í‘œ, ê³µë™ëŒ€í‘œ, etc.)


**Examples of CORRECT responses:**
- "John Doe"
- "Jane Smith"
- "ì´ìŠ¹ìš°"
- "ê¹€ì² ìˆ˜"


**Examples of INCORRECT responses:**
- "John Doe (CEO)" âŒ
- "CEO: Jane Smith" âŒ
- "ì´ìŠ¹ìš° ëŒ€í‘œ" âŒ
- "Founded by Mike Johnson" âŒ


Search the web for {company_name}'s current CEO and return ONLY the person's name.
If the CEO information is not found, return exactly: "Information not available"


Do not include any explanations, titles, or additional text.
"""
            print(f"   ğŸ” GPTê°€ ì›¹ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤: {company_name} CEO")
            response = self.web_search_llm_with_tools.invoke(search_prompt)

            if hasattr(response, 'content'):
                if isinstance(response.content, list):
                    text_content = []
                    for block in response.content:
                        if isinstance(block, dict) and block.get('type') == 'text':
                            text_content.append(block.get('text', ''))
                    extracted_info = ' '.join(text_content).strip()
                else:
                    extracted_info = response.content.strip()
            else:
                extracted_info = str(response).strip()

            cleaned_ceo_name = extract_ceo_name_only(extracted_info)

            if cleaned_ceo_name != "Information not available":
                print(f"   âœ… CEO ì´ë¦„ ì¶”ì¶œ ì„±ê³µ: {cleaned_ceo_name}")
                return cleaned_ceo_name
            else:
                print(f"   âš ï¸ CEO ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return "Information not available"

        except Exception as e:
            print(f"   âŒ GPT ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return "Information not available"

    def sup_startup_data(self, startup: GenerativeAIStartup) -> GenerativeAIStartup:
        print(f"\n{'='*60}")
        print(f"ğŸ” {startup.startup_name} ë°ì´í„° ë³´ì™„ ì‹œì‘")
        print(f"{'='*60}")

        if startup.ceo == "Information not available":
            print(f"ğŸ“ CEO ì •ë³´ ëˆ„ë½ ê°ì§€")
            sup_ceo = self.sup_missing_ceo_with_gpt(startup.startup_name)
            if sup_ceo != "Information not available":
                startup.ceo = sup_ceo
                print(f"âœ… CEO ì •ë³´ ì—…ë°ì´íŠ¸: {sup_ceo}")
        else:
            print(f"ğŸ“ ê¸°ì¡´ CEO ì •ë³´ ì •ë¦¬ ì¤‘: {startup.ceo}")
            cleaned_ceo = extract_ceo_name_only(startup.ceo)
            if cleaned_ceo != startup.ceo:
                startup.ceo = cleaned_ceo
                print(f"âœ… CEO ì´ë¦„ ì •ë¦¬ ì™„ë£Œ: {cleaned_ceo}")

        print(f"{'='*60}\n")
        return startup

    def search_startup(self, query: str, save_enriched_to_db: bool = True) -> GenerativeAIStartupList:
        if "í•œêµ­" in query or "Korea" in query:
            search_query = f"{query} Korea generative AI startup CEO current chief executive ëŒ€í‘œ angel seed series A 2015-2025"
        else:
            search_query = f"{query} generative AI startup CEO current chief executive angel seed series A 2020-2025"

        self.create_vector_db_from_web_search(search_query)

        if not self.vector_retriever:
            raise ValueError("ë²¡í„° ë¦¬íŠ¸ë¦¬ë²„ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        print("ğŸ”— ì»¤ìŠ¤í…€ RAG ì²´ì¸ì„ êµ¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")

        def custom_rag_chain(inputs: dict) -> GenerativeAIStartupList:
            context_docs = self.vector_retriever.invoke(inputs["input"])
            context_text = "\n\n".join([doc.page_content for doc in context_docs])
            formatted_prompt = self.prompt.format(
                context=context_text,
                input=inputs["input"]
            )
            result = self.structured_llm.invoke(formatted_prompt)
            return result

        print("ğŸ¤– AIê°€ ì—¬ëŸ¬ ìŠ¤íƒ€íŠ¸ì—…ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        try:
            result = custom_rag_chain({"input": query})

            print("\nğŸ”„ ì´ˆê¸° ì¶”ì¶œëœ CEO ì •ë³´ ì •ë¦¬ ì¤‘...")
            for startup in result.items:
                if startup.ceo != "Information not available":
                    cleaned = extract_ceo_name_only(startup.ceo)
                    if cleaned != startup.ceo:
                        print(f"   - {startup.startup_name}: '{startup.ceo}' -> '{cleaned}'")
                        startup.ceo = cleaned

            print("\n" + "=" * 60)
            print("ğŸ”„ GPT ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ëˆ„ë½ëœ CEO ì •ë³´ë¥¼ ë³´ì™„ ì¤‘...")
            print("=" * 60)

            with ThreadPoolExecutor(max_workers=3) as executor:
                sup_items = list(executor.map(self.sup_startup_data, result.items))

            result.items = sup_items

            if save_enriched_to_db:
                self.add_enriched_startups_to_vector_store(result.items)

            return result
        except ValidationError as ve:
            print(f"âš ï¸ êµ¬ì¡°í™” ì¶œë ¥ ê²€ì¦ ì‹¤íŒ¨: {ve}")
            raise

    def cleanup(self):
        pass


def save_result_to_json(result: GenerativeAIStartupList, output_dir: str = "./results") -> str:
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"startup_analysis_{timestamp}.json"
    filepath = os.path.join(output_dir, filename)
    result_dict = result.model_dump(exclude_none=True)
    output_data = {
        "generated_at": datetime.now().isoformat(),
        "total_startups": len(result.items),
        "data": result_dict
    }
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)
    print(f"ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
    return filepath


def main():
    rag_system = None
    try:
        rag_system = GenerativeAIStartupRAG()
        user_query = "2015ë…„ë„ ì´í›„ì— í•œêµ­ì—ì„œ ì„¤ë¦½ë˜ê³  2025ë…„ 9ì›”ê¹Œì§€ ìš´ì˜ì¤‘ì´ë©°, CEO ì •ë³´ê°€ ìˆëŠ” 50ëª… ë¯¸ë§Œì˜ ìƒì„±í˜• AI ìŠ¤íƒ€íŠ¸ì—… ì°¾ì•„ì¤˜"

        print("=" * 60)
        print("ğŸš€ ìƒì„±í˜• AI ìŠ¤íƒ€íŠ¸ì—… ê²€ìƒ‰ ì‹œìŠ¤í…œ ì‹¤í–‰")
        print("=" * 60)

        result = rag_system.search_startup(user_query, save_enriched_to_db=True)

        if isinstance(result, GenerativeAIStartupList):
            print(json.dumps(result.model_dump(exclude_none=True), ensure_ascii=False, indent=2))
            save_result_to_json(result)
            rag_system.save_vector_store("./faiss_enriched_index")
        else:
            print("ì˜ˆìƒí•˜ì§€ ëª»í•œ ê²°ê³¼:", result)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if rag_system:
            rag_system.cleanup()


if __name__ == "__main__":
    main()
