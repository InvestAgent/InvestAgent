{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1935ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-openai langchain-community langgraph tavily-python python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecfadd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b68dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Sequence, List, Dict, Any\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba0366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitorAgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    target_company: str\n",
    "    target_tech: Dict\n",
    "    competitors: List[Dict]\n",
    "    market_info: Dict\n",
    "    research_results: Dict\n",
    "    competitor_scores: List[Dict]\n",
    "    swot: Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41026a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON ì¶”ì¶œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_json_from_llm_response(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    LLM ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ\n",
    "    - ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°\n",
    "    - ì•ë’¤ ê³µë°±/í…ìŠ¤íŠ¸ ì œê±°\n",
    "    \"\"\"\n",
    "    # ë§ˆí¬ë‹¤ìš´ ì œê±° (```json ... ``` ë˜ëŠ” ``` ... ```)\n",
    "    text = re.sub(r'```(?:json)?\\s*', '', text)\n",
    "    text = re.sub(r'\\s*```', '', text)\n",
    "    \n",
    "    # ì•ë’¤ ê³µë°± ì œê±°\n",
    "    text = text.strip()\n",
    "    \n",
    "    # JSON ê°ì²´ë§Œ ì¶”ì¶œ (ì²« { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€)\n",
    "    json_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "    if json_match:\n",
    "        text = json_match.group()\n",
    "    \n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨\")\n",
    "        print(f\"ì›ë³¸ í…ìŠ¤íŠ¸:\\n{text[:500]}\")  # ì²˜ìŒ 500ìë§Œ\n",
    "        raise e\n",
    "\n",
    "print(\"JSON ì¶”ì¶œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48aef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_state(state: CompetitorAgentState) -> CompetitorAgentState:\n",
    "    messages = state[\"messages\"]\n",
    "    data = json.loads(messages[0].content) if isinstance(messages[0].content, str) else messages[0].content\n",
    "    \n",
    "    assert \"company\" in data, \"íƒ€ê²Ÿ ê¸°ì—…ëª… ëˆ„ë½\"\n",
    "    assert \"from_tech_summary\" in data, \"ê¸°ìˆ  ìš”ì•½ ëˆ„ë½\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"target_company\": data[\"company\"],\n",
    "        \"target_tech\": data[\"from_tech_summary\"],\n",
    "        \"competitors\": [],  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘ (search_competitors_hybridì—ì„œ ì±„ì›€)\n",
    "        \"market_info\": data.get(\"from_market\", {}),\n",
    "        \"research_results\": {},\n",
    "        \"competitor_scores\": [],\n",
    "        \"swot\": {}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d13ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_competitors_hybrid(state: CompetitorAgentState) -> CompetitorAgentState:\n",
    "    \"\"\"\n",
    "    Vector DBì—ì„œ ê²½ìŸì‚¬ ê²€ìƒ‰ + ì›¹ ê²€ìƒ‰ ë³´ì™„\n",
    "    - Vector DBì—ì„œ ìœ ì‚¬ ìŠ¤íƒ€íŠ¸ì—… ê²€ìƒ‰ (ìµœëŒ€ 2ê°œ)\n",
    "    - ë¶€ì¡±í•˜ë©´ ì›¹ ê²€ìƒ‰\n",
    "    - ëŒ€ê¸°ì—… 2ê°œ ì¶”ê°€\n",
    "    - ì´ 4ê°œ ê²½ìŸì‚¬\n",
    "    \"\"\"\n",
    "    target = state[\"target_company\"]\n",
    "    target_tech = state[\"target_tech\"]\n",
    "    \n",
    "    # BGE ì„ë² ë”© ì´ˆê¸°í™” (ê²€ìƒ‰ìš©)\n",
    "    embeddings = HuggingFaceBgeEmbeddings(\n",
    "        model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "        model_kwargs={\"device\": \"cpu\"},\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    \n",
    "    startup_competitors = []\n",
    "    \n",
    "    try:\n",
    "        # ê¸°ì¡´ Vector DB ë¡œë“œ\n",
    "        vectorstore = FAISS.load_local(\n",
    "            \"competitor_vectordb\",  # ì´ë¯¸ êµ¬ì¶•ëœ DB ê²½ë¡œ\n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        \n",
    "        # ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        search_query = f\"{target} {target_tech.get('core_tech', '')} AI startup\"\n",
    "        \n",
    "        # ìœ ì‚¬ë„ ê²€ìƒ‰ (k=2)\n",
    "        docs = vectorstore.similarity_search(search_query, k=2)\n",
    "        \n",
    "        for doc in docs:\n",
    "            startup_competitors.append({\n",
    "                \"company\": doc.metadata.get(\"company\", \"Unknown\"),\n",
    "                \"focus\": doc.metadata.get(\"focus\", \"N/A\"),\n",
    "                \"country\": doc.metadata.get(\"country\", \"N/A\"),\n",
    "                \"recent_investment\": doc.metadata.get(\"recent_investment\", \"N/A\"),\n",
    "                \"founded_year\": doc.metadata.get(\"founded_year\", \"N/A\"),\n",
    "                \"website\": doc.metadata.get(\"website\", \"\"),\n",
    "                \"detailed_info\": doc.metadata.get(\"detailed_info\", \"\"),\n",
    "                \"source\": \"vectordb\"\n",
    "            })\n",
    "        \n",
    "        print(f\"âœ… Vector DB: {len(startup_competitors)}ê°œ ë°œê²¬\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"âš ï¸ Vector DB íŒŒì¼ ì—†ìŒ. ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´\")\n",
    "        startup_competitors = []\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Vector DB ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        startup_competitors = []\n",
    "    \n",
    "    # 2ê°œ ë¯¸ë§Œì´ë©´ ì›¹ì—ì„œ ë³´ì¶©\n",
    "    if len(startup_competitors) < 2:\n",
    "        needed = 2 - len(startup_competitors)\n",
    "        web_startups = search_web_competitors(\n",
    "            target, \n",
    "            target_tech.get('core_tech', ''), \n",
    "            max_results=needed,\n",
    "            exclude_companies=[c[\"company\"] for c in startup_competitors]\n",
    "        )\n",
    "        startup_competitors.extend(web_startups)\n",
    "        print(f\"âœ… ì›¹ ê²€ìƒ‰: {len(web_startups)}ê°œ ì¶”ê°€\")\n",
    "    \n",
    "    # ëŒ€ê¸°ì—… 2ê°œ\n",
    "    bigtech = select_relevant_bigtech(target, target_tech)\n",
    "    \n",
    "    # ìµœì¢… 4ê°œ\n",
    "    all_competitors = startup_competitors[:2] + bigtech[:2]\n",
    "    \n",
    "    print(f\"ğŸ“Š ìµœì¢… ê²½ìŸì‚¬: {[c['company'] for c in all_competitors]}\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"competitors\": all_competitors,\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            HumanMessage(content=f\"ê²½ìŸì‚¬ 4ê°œ ì„ ì • (ìŠ¤íƒ€íŠ¸ì—… {len(startup_competitors[:2])}, ëŒ€ê¸°ì—… {len(bigtech[:2])})\")\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84173a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web_competitors(target: str, core_tech: str, max_results: int = 2, exclude_companies: list = None) -> list:\n",
    "    \"\"\"\n",
    "    ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ê²½ìŸì‚¬ ë°œêµ´\n",
    "    \n",
    "    Args:\n",
    "        target: íƒ€ê²Ÿ ê¸°ì—…ëª…\n",
    "        core_tech: í•µì‹¬ ê¸°ìˆ \n",
    "        max_results: ì°¾ì„ ê²½ìŸì‚¬ ìˆ˜\n",
    "        exclude_companies: ì œì™¸í•  ê¸°ì—… ë¦¬ìŠ¤íŠ¸ (ì´ë¯¸ ì°¾ì€ ê²½ìŸì‚¬)\n",
    "    \n",
    "    Returns:\n",
    "        list: ê²½ìŸì‚¬ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    if exclude_companies is None:\n",
    "        exclude_companies = []\n",
    "    \n",
    "    search_tool = TavilySearchResults(max_results=5)\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±\n",
    "    search_query = f\"{target} competitors {core_tech} AI startup similar companies\"\n",
    "    \n",
    "    try:\n",
    "        # ì›¹ ê²€ìƒ‰ ì‹¤í–‰\n",
    "        results = search_tool.invoke({\"query\": search_query})\n",
    "        \n",
    "        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í†µí•©\n",
    "        context = \"\\n\\n\".join([\n",
    "            f\"[{r.get('title', 'N/A')}]\\n{r.get('content', '')}\\nURL: {r.get('url', '')}\"\n",
    "            for r in results\n",
    "        ])\n",
    "        \n",
    "        # LLMìœ¼ë¡œ ê²½ìŸì‚¬ ì¶”ì¶œ\n",
    "        prompt = f\"\"\"\n",
    "ë‹¤ìŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ {target}ì˜ ê²½ìŸì‚¬ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.\n",
    "\n",
    "íƒ€ê²Ÿ ê¸°ì—…: {target}\n",
    "í•µì‹¬ ê¸°ìˆ : {core_tech}\n",
    "\n",
    "ê²€ìƒ‰ ê²°ê³¼:\n",
    "{context}\n",
    "\n",
    "ì œì™¸í•  ê¸°ì—…: {', '.join(exclude_companies) if exclude_companies else 'ì—†ìŒ'}\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "1. {max_results}ê°œì˜ ê²½ìŸì‚¬ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”\n",
    "2. ì œì™¸ ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ê¸°ì—…ë§Œ ì„ ì •\n",
    "3. AI/ê¸°ìˆ  ìŠ¤íƒ€íŠ¸ì—… ìœ„ì£¼ë¡œ ì„ ì •\n",
    "4. ê° ê¸°ì—…ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨:\n",
    "   - company: ê¸°ì—…ëª…\n",
    "   - focus: ì£¼ë ¥ ë¶„ì•¼/ì œí’ˆ (í•œ ì¤„)\n",
    "   - country: êµ­ê°€\n",
    "   - recent_investment: ìµœê·¼ íˆ¬ì ì •ë³´ (ì•Œ ìˆ˜ ì—†ìœ¼ë©´ \"N/A\")\n",
    "   - founded_year: ì„¤ë¦½ ì—°ë„ (ì•Œ ìˆ˜ ì—†ìœ¼ë©´ \"N/A\")\n",
    "   - website: ì›¹ì‚¬ì´íŠ¸ URL (ìˆìœ¼ë©´)\n",
    "\n",
    "ìˆœìˆ˜ JSONë§Œ ì¶œë ¥:\n",
    "{{\"competitors\": [\n",
    "    {{\"company\": \"CompanyA\", \"focus\": \"AI video generation\", \"country\": \"US\", \"recent_investment\": \"Series B $50M\", \"founded_year\": \"2021\", \"website\": \"https://example.com\"}},\n",
    "    {{\"company\": \"CompanyB\", \"focus\": \"Text-to-video AI\", \"country\": \"UK\", \"recent_investment\": \"Seed $10M\", \"founded_year\": \"2022\", \"website\": \"\"}}\n",
    "]}}\n",
    "\"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        data = extract_json_from_llm_response(response.content)\n",
    "        \n",
    "        # ê²°ê³¼ ê°€ê³µ\n",
    "        web_competitors = []\n",
    "        for comp in data.get(\"competitors\", [])[:max_results]:\n",
    "            # ì œì™¸ ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ê²½ìŸì‚¬ë§Œ ì¶”ê°€\n",
    "            if comp[\"company\"] not in exclude_companies:\n",
    "                web_competitors.append({\n",
    "                    \"company\": comp[\"company\"],\n",
    "                    \"focus\": comp.get(\"focus\", \"N/A\"),\n",
    "                    \"country\": comp.get(\"country\", \"N/A\"),\n",
    "                    \"recent_investment\": comp.get(\"recent_investment\", \"N/A\"),\n",
    "                    \"founded_year\": comp.get(\"founded_year\", \"N/A\"),\n",
    "                    \"website\": comp.get(\"website\", \"\"),\n",
    "                    \"detailed_info\": \"\",\n",
    "                    \"source\": \"web_search\"\n",
    "                })\n",
    "        \n",
    "        print(f\"âœ… ì›¹ ê²€ìƒ‰ìœ¼ë¡œ {len(web_competitors)}ê°œ ê²½ìŸì‚¬ ë°œê²¬\")\n",
    "        return web_competitors\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e2be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_bigtech(target: str, target_tech: dict) -> list:\n",
    "    \"\"\"\n",
    "    íƒ€ê²Ÿ ê¸°ì—…ê³¼ ê´€ë ¨ëœ ëŒ€ê¸°ì—… 2ê°œ ì„ ì •\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "íƒ€ê²Ÿ ê¸°ì—…: {target}\n",
    "í•µì‹¬ ê¸°ìˆ : {target_tech.get('core_tech', 'N/A')}\n",
    "ê°•ì : {', '.join(target_tech.get('strengths', []))}\n",
    "\n",
    "ë‹¤ìŒ ëŒ€ê¸°ì—… ì¤‘ íƒ€ê²Ÿê³¼ ê°€ì¥ ê´€ë ¨ ë†’ì€ 2ê°œë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
    "\n",
    "ëŒ€ê¸°ì—… ëª©ë¡:\n",
    "- OpenAI: GPT, ChatGPT, DALL-E\n",
    "- Meta: Llama, AI research\n",
    "- Google: Gemini, DeepMind, Imagen\n",
    "- Microsoft: Copilot, Azure AI\n",
    "- Anthropic: Claude\n",
    "- Amazon: AWS AI, Alexa\n",
    "- Adobe: Firefly, Sensei\n",
    "- Stability AI: Stable Diffusion\n",
    "\n",
    "ìˆœìˆ˜ JSONë§Œ ì¶œë ¥:\n",
    "{{\"companies\": [{{\"company\": \"OpenAI\", \"focus\": \"LLM, ChatGPT\", \"reasoning\": \"ì´ìœ \"}}, {{\"company\": \"Google\", \"focus\": \"Gemini\", \"reasoning\": \"ì´ìœ \"}}]}}\n",
    "\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # JSON ì¶”ì¶œ í•¨ìˆ˜ ì‚¬ìš©\n",
    "    data = extract_json_from_llm_response(response.content)\n",
    "    \n",
    "    bigtech = []\n",
    "    for comp in data.get(\"companies\", [])[:2]:\n",
    "        bigtech.append({\n",
    "            \"company\": comp[\"company\"],\n",
    "            \"focus\": comp[\"focus\"],\n",
    "            \"country\": \"US\",\n",
    "            \"recent_investment\": \"ëŒ€ê¸°ì—… (ìƒì¥)\",\n",
    "            \"source\": \"bigtech\",\n",
    "            \"reasoning\": comp.get(\"reasoning\", \"\")\n",
    "        })\n",
    "    \n",
    "    print(f\"âœ… ëŒ€ê¸°ì—… ì„ ì •: {[c['company'] for c in bigtech]}\")\n",
    "    return bigtech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af816a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_research_competitors(state: CompetitorAgentState) -> CompetitorAgentState:\n",
    "    target = state[\"target_company\"]\n",
    "    competitors = state[\"competitors\"]\n",
    "    search_tool = TavilySearchResults(max_results=3)\n",
    "    research_data = {}\n",
    "    \n",
    "    for comp in competitors:\n",
    "        comp_name = comp[\"company\"]\n",
    "        search_query = f\"{comp_name} AI startup product features customers funding\"\n",
    "        \n",
    "        try:\n",
    "            results = search_tool.invoke({\"query\": search_query})\n",
    "            context = \"\\n\\n\".join([\n",
    "                f\"[{r.get('title', 'N/A')}]\\n{r.get('content', '')}\\nURL: {r.get('url', '')}\"\n",
    "                for r in results\n",
    "            ])\n",
    "            \n",
    "            llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "            summary = llm.invoke([HumanMessage(content=f\"\"\"\n",
    "ë‹¤ìŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”:\n",
    "\n",
    "ê²½ìŸì‚¬: {comp_name}\n",
    "ì£¼ë ¥ ë¶„ì•¼: {comp.get('focus', 'N/A')}\n",
    "\n",
    "ê²€ìƒ‰ ê²°ê³¼:\n",
    "{context}\n",
    "\n",
    "ë‹¤ìŒ í•­ëª©ì„ ê°„ê²°í•˜ê²Œ ì •ë¦¬ (ê° 2-3ë¬¸ì¥):\n",
    "1. ì œí’ˆ/ì„œë¹„ìŠ¤ íŠ¹ì§•\n",
    "2. ì£¼ìš” ê³ ê°ì¸µ/íƒ€ê²Ÿ ì‹œì¥\n",
    "3. ìµœê·¼ ë™í–¥ (íˆ¬ì, ì œí’ˆ ì¶œì‹œ ë“±)\n",
    "4. ê¸°ìˆ ì  ê°•ì \n",
    "\"\"\")])\n",
    "            \n",
    "            research_data[comp_name] = summary.content\n",
    "            print(f\"âœ… {comp_name} ë¦¬ì„œì¹˜ ì™„ë£Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ ({comp_name}): {e}\")\n",
    "            research_data[comp_name] = f\"ì£¼ë ¥ ë¶„ì•¼: {comp.get('focus', 'N/A')}\"\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"research_results\": research_data,\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            HumanMessage(content=f\"ì›¹ ë¦¬ì„œì¹˜ ì™„ë£Œ: {len(competitors)}ê°œ ê²½ìŸì‚¬\")\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a3787b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_competitive_positioning(state: CompetitorAgentState) -> CompetitorAgentState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    target = state[\"target_company\"]\n",
    "    target_tech = state[\"target_tech\"]\n",
    "    competitors = state[\"competitors\"]\n",
    "    research = state[\"research_results\"]\n",
    "    \n",
    "    scored_list = []\n",
    "    \n",
    "    for comp in competitors:\n",
    "        prompt = f\"\"\"\n",
    "ê²½ìŸì‚¬ë¥¼ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš” (ê° 0-10ì ):\n",
    "1. overlap: íƒ€ê²Ÿ({target})ê³¼ ì‹œì¥ ì¤‘ë³µë„\n",
    "2. differentiation: ê²½ìŸì‚¬ë§Œì˜ ì°¨ë³„í™”\n",
    "3. moat: ì§„ì…ì¥ë²½\n",
    "4. positioning: í•œ ë¬¸ì¥ ìš”ì•½\n",
    "\n",
    "íƒ€ê²Ÿ í•µì‹¬ ê¸°ìˆ : {target_tech.get('core_tech', 'N/A')}\n",
    "ê²½ìŸì‚¬: {comp[\"company\"]}\n",
    "ì£¼ë ¥ ë¶„ì•¼: {comp.get('focus', 'N/A')}\n",
    "ìµœê·¼ íˆ¬ì: {comp.get('recent_investment', 'N/A')}\n",
    "\n",
    "ì›¹ ë¦¬ì„œì¹˜:\n",
    "{research.get(comp[\"company\"], \"ì •ë³´ ì—†ìŒ\")}\n",
    "\n",
    "ìˆœìˆ˜ JSONë§Œ ì¶œë ¥:\n",
    "{{\"company\": \"{comp['company']}\", \"overlap\": 7.5, \"differentiation\": 6.0, \"moat\": 5.5, \"positioning\": \"í•œ ë¬¸ì¥\"}}\n",
    "\"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        score_data = extract_json_from_llm_response(response.content)  # ì—¬ê¸° ìˆ˜ì •\n",
    "        scored_list.append(score_data)\n",
    "        print(f\"âœ… {comp['company']} í‰ê°€ ì™„ë£Œ\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"competitor_scores\": scored_list,\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            HumanMessage(content=f\"ê²½ìŸ êµ¬ë„ ë¶„ì„ ì™„ë£Œ: {len(scored_list)}ê°œ\")\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e70a365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_swot_analysis(state: CompetitorAgentState) -> CompetitorAgentState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    target = state[\"target_company\"]\n",
    "    target_tech = state[\"target_tech\"]\n",
    "    competitor_scores = state[\"competitor_scores\"]\n",
    "    market_info = state[\"market_info\"]\n",
    "    research_results = state[\"research_results\"]  # ì¶”ê°€: ê²½ìŸì‚¬ ìƒì„¸ ì •ë³´ í™œìš©\n",
    "    \n",
    "    # ê²½ìŸì‚¬ ìš”ì•½ ìƒì„±\n",
    "    competitor_summary = \"\\n\".join([\n",
    "        f\"- {score['company']}: overlap {score['overlap']}/10, moat {score['moat']}/10\\n  í¬ì§€ì…”ë‹: {score['positioning']}\"\n",
    "        for score in competitor_scores\n",
    "    ])\n",
    "    \n",
    "    swot_prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ë²¤ì²˜ íˆ¬ì ì‹¬ì‚¬ì—­ì…ë‹ˆë‹¤. ë‹¤ìŒ ìŠ¤íƒ€íŠ¸ì—…ì— ëŒ€í•œ íˆ¬ì íŒë‹¨ì„ ìœ„í•œ ê²½ìŸ ë¶„ì„ ê¸°ë°˜ SWOTì„ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "## íƒ€ê²Ÿ ê¸°ì—… ì •ë³´\n",
    "- ê¸°ì—…ëª…: {target}\n",
    "- í•µì‹¬ ê¸°ìˆ : {target_tech.get('core_tech', 'N/A')}\n",
    "- ê¸°ìˆ ì  ê°•ì : {', '.join(target_tech.get('strengths', []))}\n",
    "- ê¸°ìˆ ì  ì•½ì : {', '.join(target_tech.get('weaknesses', []))}\n",
    "\n",
    "## ì‹œì¥ í™˜ê²½\n",
    "{json.dumps(market_info, indent=2, ensure_ascii=False)}\n",
    "\n",
    "## ê²½ìŸì‚¬ ë¶„ì„ ê²°ê³¼\n",
    "{competitor_summary}\n",
    "\n",
    "## ê²½ìŸì‚¬ ìƒì„¸ ë¦¬ì„œì¹˜\n",
    "{json.dumps(research_results, indent=2, ensure_ascii=False)[:2000]}\n",
    "\n",
    "---\n",
    "\n",
    "íˆ¬ì ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ **êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ** SWOT ë¶„ì„ì„ ì‘ì„±í•˜ì„¸ìš”:\n",
    "\n",
    "### Strengths (ê²½ìŸ ìš°ìœ„, 5-7ê°œ)\n",
    "- ê²½ìŸì‚¬ ëŒ€ë¹„ **ëª…í™•íˆ ìš°ì›”í•œ ì **\n",
    "- ì •ëŸ‰ì  ê·¼ê±° í¬í•¨ (ì˜ˆ: \"ë Œë”ë§ ì†ë„ ê²½ìŸì‚¬ ëŒ€ë¹„ 2ë°°\", \"ê³ ê° ë§Œì¡±ë„ 95%\")\n",
    "- ë°©ì–´ ê°€ëŠ¥í•œ ê¸°ìˆ ì /ì‹œì¥ì  ìš°ìœ„\n",
    "- íˆ¬ìì ê´€ì : \"ì´ íšŒì‚¬ê°€ ì™œ ì´ê¸¸ ìˆ˜ ìˆëŠ”ê°€?\"\n",
    "\n",
    "### Weaknesses (íˆ¬ì ë¦¬ìŠ¤í¬, 5-7ê°œ)\n",
    "- ê²½ìŸì‚¬ ëŒ€ë¹„ **ëª…í™•íˆ ë¶ˆë¦¬í•œ ì **\n",
    "- ì •ëŸ‰ì  ë¦¬ìŠ¤í¬ (ì˜ˆ: \"ìš´ì˜ë¹„ìš© ë§¤ì¶œì˜ 70%\", \"ëŒ€ê¸°ì—… ëŒ€ë¹„ ìë³¸ë ¥ 1/100\")\n",
    "- ë‹¨ê¸°ì ìœ¼ë¡œ ê°œì„  ì–´ë ¤ìš´ êµ¬ì¡°ì  ì•½ì \n",
    "- íˆ¬ìì ê´€ì : \"ì–´ë–¤ ë¦¬ìŠ¤í¬ë¡œ ì‹¤íŒ¨í•  ìˆ˜ ìˆëŠ”ê°€?\"\n",
    "\n",
    "### Opportunities (ì„±ì¥ ê¸°íšŒ, 5-7ê°œ)\n",
    "- ì‹œì¥ ì„±ì¥ ê¸°íšŒ (êµ¬ì²´ì  ìˆ˜ì¹˜)\n",
    "- ê²½ìŸì‚¬ê°€ ë†“ì¹˜ê³  ìˆëŠ” í‹ˆìƒˆ\n",
    "- ê¸°ìˆ /ì‹œì¥ íŠ¸ë Œë“œ í™œìš© ë°©ì•ˆ\n",
    "- íŒŒíŠ¸ë„ˆì‹­, M&A, ì‹ ê·œ ì‹œì¥ ì§„ì¶œ ê°€ëŠ¥ì„±\n",
    "- íˆ¬ìì ê´€ì : \"ì–´ë–»ê²Œ 10ë°° ì„±ì¥í•  ìˆ˜ ìˆëŠ”ê°€?\"\n",
    "\n",
    "### Threats (ìƒì¡´ ìœ„í˜‘, 5-7ê°œ)\n",
    "- ëŒ€ê¸°ì—… ì§„ì… ìœ„í˜‘ (OpenAI, Google ë“±)\n",
    "- ê¸°ìˆ  commoditization ë¦¬ìŠ¤í¬\n",
    "- ê·œì œ, ì €ì‘ê¶Œ ì´ìŠˆ\n",
    "- ê²½ìŸ ì‹¬í™”ë¡œ ì¸í•œ ë§ˆì§„ ì¶•ì†Œ\n",
    "- íˆ¬ìì ê´€ì : \"ë¬´ì—‡ì´ ì´ íšŒì‚¬ë¥¼ ì£½ì¼ ìˆ˜ ìˆëŠ”ê°€?\"\n",
    "\n",
    "---\n",
    "\n",
    "**ì‘ì„± ì›ì¹™:**\n",
    "1. ê° í•­ëª©ì€ **êµ¬ì²´ì  ê·¼ê±°**ì™€ í•¨ê»˜ ì‘ì„± (ì¶”ìƒì  í‘œí˜„ ê¸ˆì§€)\n",
    "2. íˆ¬ì ì˜ì‚¬ê²°ì •ì— ì§ì ‘ í™œìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€\n",
    "3. ê²½ìŸì‚¬ ë¶„ì„ ê²°ê³¼ë¥¼ **ëª…ì‹œì ìœ¼ë¡œ ë°˜ì˜**\n",
    "4. ì‹œì¥ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¸ìš©\n",
    "\n",
    "ìˆœìˆ˜ JSONë§Œ ì¶œë ¥:\n",
    "{{\n",
    "  \"strengths\": [\n",
    "    \"ì˜ìƒ ìƒì„± íŠ¹í™” AI ëª¨ë¸ë¡œ ê²½ìŸì‚¬(Pika Labs) ëŒ€ë¹„ ë Œë”ë§ í’ˆì§ˆ 15% ìš°ìˆ˜\",\n",
    "    \"í¬ë¦¬ì—ì´í„° ì¤‘ì‹¬ UXë¡œ ì‚¬ìš©ì ì´íƒˆë¥  5% (ì—…ê³„ í‰ê·  20%)\",\n",
    "    \"...5-7ê°œ\"\n",
    "  ],\n",
    "  \"weaknesses\": [\n",
    "    \"GPU ì¸í”„ë¼ ë¹„ìš©ì´ ë§¤ì¶œì˜ 60%ë¡œ ê²½ìŸì‚¬(30%) ëŒ€ë¹„ 2ë°° ë†’ìŒ\",\n",
    "    \"OpenAI, Adobe ë“± ëŒ€ê¸°ì—… ëŒ€ë¹„ R&D íˆ¬ì 1/50 ìˆ˜ì¤€\",\n",
    "    \"...5-7ê°œ\"\n",
    "  ],\n",
    "  \"opportunities\": [\n",
    "    \"ìƒì„±í˜• AI ë¹„ë””ì˜¤ ì‹œì¥ 2024-2027 CAGR 150% ì„±ì¥ ì˜ˆìƒ\",\n",
    "    \"í¬ë¦¬ì—ì´í„° ì´ì½”ë…¸ë¯¸ ì‹œì¥ $104B â†’ $480B (2027) í™•ëŒ€\",\n",
    "    \"...5-7ê°œ\"\n",
    "  ],\n",
    "  \"threats\": [\n",
    "    \"OpenAI Sora ì¶œì‹œ ì‹œ ê°€ê²© ê²½ìŸìœ¼ë¡œ ë§ˆì§„ 50% ì¶•ì†Œ ìœ„í—˜\",\n",
    "    \"ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸(Stable Video Diffusion) í’ˆì§ˆ í–¥ìƒìœ¼ë¡œ ë¬´ë£Œ ëŒ€ì²´ì¬ ì¦ê°€\",\n",
    "    \"...5-7ê°œ\"\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=swot_prompt)])\n",
    "    swot_data = extract_json_from_llm_response(response.content)\n",
    "    \n",
    "    # ê²€ì¦: ê° í•­ëª©ì´ ìµœì†Œ 4ê°œ ì´ìƒì¸ì§€ í™•ì¸\n",
    "    for key in [\"strengths\", \"weaknesses\", \"opportunities\", \"threats\"]:\n",
    "        if len(swot_data.get(key, [])) < 4:\n",
    "            print(f\"âš ï¸ {key} í•­ëª©ì´ {len(swot_data.get(key, []))}ê°œë¡œ ë¶€ì¡±í•¨\")\n",
    "    \n",
    "    print(\"âœ… SWOT ë¶„ì„ ì™„ë£Œ\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"swot\": swot_data,\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            HumanMessage(content=\"SWOT ë¶„ì„ ì™„ë£Œ\")\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31158a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_output(state: CompetitorAgentState) -> CompetitorAgentState:\n",
    "    output = {\n",
    "        \"company\": state[\"target_company\"],\n",
    "        \"competitors_analysis\": state[\"competitor_scores\"],\n",
    "        \"swot\": state[\"swot\"],\n",
    "        \"generated_at\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            HumanMessage(content=json.dumps(output, indent=2, ensure_ascii=False))\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59818166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¸ë˜í”„ ì¬êµ¬ì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def create_competitor_analysis_graph():\n",
    "    workflow = StateGraph(CompetitorAgentState)\n",
    "    \n",
    "    workflow.add_node(\"initialize\", initialize_state)\n",
    "    workflow.add_node(\"search_competitors\", search_competitors_hybrid)  # ì¶”ê°€\n",
    "    workflow.add_node(\"web_research\", web_research_competitors)\n",
    "    workflow.add_node(\"analyze_positioning\", analyze_competitive_positioning)\n",
    "    workflow.add_node(\"swot_analysis\", generate_swot_analysis)\n",
    "    workflow.add_node(\"finalize\", finalize_output)\n",
    "    \n",
    "    workflow.add_edge(START, \"initialize\")\n",
    "    workflow.add_edge(\"initialize\", \"search_competitors\")      # ë³€ê²½\n",
    "    workflow.add_edge(\"search_competitors\", \"web_research\")    # ì¶”ê°€\n",
    "    workflow.add_edge(\"web_research\", \"analyze_positioning\")\n",
    "    workflow.add_edge(\"analyze_positioning\", \"swot_analysis\")\n",
    "    workflow.add_edge(\"swot_analysis\", \"finalize\")\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "graph = create_competitor_analysis_graph()\n",
    "print(\"ê·¸ë˜í”„ ì¬êµ¬ì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1a03c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output_to_json(output_json: str, filename: str = \"competitor_analysis_output.json\"):\n",
    "    \"\"\"ì¶œë ¥ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "    output = json.loads(output_json)\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"ì €ì¥ ì™„ë£Œ: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc6dc3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Vector DB ë¡œë“œ ì‹¤íŒ¨: Error in faiss::FileIOReader::FileIOReader(const char *) at /Users/runner/work/faiss-wheels/faiss-wheels/third-party/faiss/faiss/impl/io.cpp:70: Error: 'f' failed: could not open competitor_vectordb/index.faiss for reading: No such file or directory\n",
      "âœ… ì›¹ ê²€ìƒ‰ìœ¼ë¡œ 2ê°œ ê²½ìŸì‚¬ ë°œê²¬\n",
      "âœ… ì›¹ ê²€ìƒ‰: 2ê°œ ì¶”ê°€\n",
      "âœ… ëŒ€ê¸°ì—… ì„ ì •: ['OpenAI', 'Adobe']\n",
      "ğŸ“Š ìµœì¢… ê²½ìŸì‚¬: ['KlingAI', 'Luma AI', 'OpenAI', 'Adobe']\n",
      "âœ… KlingAI ë¦¬ì„œì¹˜ ì™„ë£Œ\n",
      "âœ… Luma AI ë¦¬ì„œì¹˜ ì™„ë£Œ\n",
      "âœ… OpenAI ë¦¬ì„œì¹˜ ì™„ë£Œ\n",
      "âœ… Adobe ë¦¬ì„œì¹˜ ì™„ë£Œ\n",
      "âœ… KlingAI í‰ê°€ ì™„ë£Œ\n",
      "âœ… Luma AI í‰ê°€ ì™„ë£Œ\n",
      "âœ… OpenAI í‰ê°€ ì™„ë£Œ\n",
      "âœ… Adobe í‰ê°€ ì™„ë£Œ\n",
      "âœ… SWOT ë¶„ì„ ì™„ë£Œ\n",
      "{\n",
      "  \"company\": \"Runway\",\n",
      "  \"competitors_analysis\": [\n",
      "    {\n",
      "      \"company\": \"KlingAI\",\n",
      "      \"overlap\": 7.5,\n",
      "      \"differentiation\": 6.0,\n",
      "      \"moat\": 5.5,\n",
      "      \"positioning\": \"KlingAIëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•˜ëŠ” AI ë¹„ë””ì˜¤ ìƒì„± í”Œë«í¼ì…ë‹ˆë‹¤.\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"Luma AI\",\n",
      "      \"overlap\": 7.5,\n",
      "      \"differentiation\": 6.0,\n",
      "      \"moat\": 5.5,\n",
      "      \"positioning\": \"Luma AIëŠ” í…ìŠ¤íŠ¸ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•˜ëŠ” í˜ì‹ ì ì¸ AI í”Œë«í¼ìœ¼ë¡œ, ì½˜í…ì¸  ì œì‘ìì™€ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ë¥¼ ìœ„í•œ ë§ì¶¤í˜• ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"OpenAI\",\n",
      "      \"overlap\": 7.5,\n",
      "      \"differentiation\": 6.0,\n",
      "      \"moat\": 5.5,\n",
      "      \"positioning\": \"OpenAIëŠ” ëŒ€í™”í˜• AIë¥¼ í†µí•´ ì‚¬ìš©ì ë§ì¶¤í˜• ì‡¼í•‘ ê²½í—˜ì„ ì œê³µí•˜ëŠ” í˜ì‹ ì ì¸ í”Œë«í¼ì´ë‹¤.\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"Adobe\",\n",
      "      \"overlap\": 7.5,\n",
      "      \"differentiation\": 6.0,\n",
      "      \"moat\": 5.5,\n",
      "      \"positioning\": \"AdobeëŠ” ë‹¤ì–‘í•œ AI ë„êµ¬ë¥¼ í†µí•´ ëŒ€ê¸°ì—… ê³ ê°ì„ ëŒ€ìƒìœ¼ë¡œ ì°½ì˜ì ì´ê³  íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ëŠ” ì„ ë„ì ì¸ í”Œë«í¼ì´ë‹¤.\"\n",
      "    }\n",
      "  ],\n",
      "  \"swot\": {\n",
      "    \"strengths\": [\n",
      "      \"ì˜ìƒ ìƒì„± íŠ¹í™” AI ëª¨ë¸ë¡œ ê²½ìŸì‚¬ ëŒ€ë¹„ ë Œë”ë§ í’ˆì§ˆ 15% ìš°ìˆ˜\",\n",
      "      \"í¬ë¦¬ì—ì´í„° ì¤‘ì‹¬ UXë¡œ ì‚¬ìš©ì ì´íƒˆë¥  5% (ì—…ê³„ í‰ê·  20%)\",\n",
      "      \"í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ë³€í™˜ ì†ë„ê°€ ê²½ìŸì‚¬ ëŒ€ë¹„ 30% ë¹ ë¦„\",\n",
      "      \"AI ê¸°ë°˜ì˜ ìë™í™”ëœ ì½˜í…ì¸  ìƒì„± ê¸°ëŠ¥ìœ¼ë¡œ ì œì‘ ì‹œê°„ 50% ë‹¨ì¶•\",\n",
      "      \"ë‹¤ì–‘í•œ API í†µí•© ê°€ëŠ¥ì„±ìœ¼ë¡œ ê°œë°œì ë° ê¸°ì—… ê³ ê° ìœ ì¹˜ ìš©ì´\",\n",
      "      \"ê³ ê° ë§Œì¡±ë„ 90%ë¡œ, ê²½ìŸì‚¬ í‰ê·  75%ë³´ë‹¤ ë†’ìŒ\"\n",
      "    ],\n",
      "    \"weaknesses\": [\n",
      "      \"GPU ì¸í”„ë¼ ë¹„ìš©ì´ ë§¤ì¶œì˜ 60%ë¡œ ê²½ìŸì‚¬ ëŒ€ë¹„ 2ë°° ë†’ìŒ\",\n",
      "      \"OpenAI, Adobe ë“± ëŒ€ê¸°ì—… ëŒ€ë¹„ R&D íˆ¬ì 1/50 ìˆ˜ì¤€\",\n",
      "      \"ë°ì´í„° íˆ¬ëª…ì„± ë¶€ì¡±ìœ¼ë¡œ ê³ ê° ì‹ ë¢°ë„ ì €í•˜ ê°€ëŠ¥ì„±\",\n",
      "      \"ê¸°ìˆ ì  ì§€ì› ì¸ë ¥ì´ ë¶€ì¡±í•˜ì—¬ ê³ ê° ëŒ€ì‘ ì†ë„ ëŠë¦¼\",\n",
      "      \"ì‹œì¥ ì ìœ ìœ¨ì´ 10%ë¡œ ê²½ìŸì‚¬ í‰ê·  25%ì— ë¯¸ì¹˜ì§€ ëª»í•¨\",\n",
      "      \"ë¸Œëœë“œ ì¸ì§€ë„ ë‚®ì•„ ì‹ ê·œ ê³ ê° ìœ ì¹˜ì— ì–´ë ¤ì›€\"\n",
      "    ],\n",
      "    \"opportunities\": [\n",
      "      \"ìƒì„±í˜• AI ë¹„ë””ì˜¤ ì‹œì¥ 2024-2027 CAGR 150% ì„±ì¥ ì˜ˆìƒ\",\n",
      "      \"í¬ë¦¬ì—ì´í„° ì´ì½”ë…¸ë¯¸ ì‹œì¥ $104B â†’ $480B (2027) í™•ëŒ€\",\n",
      "      \"ì†Œì…œ ë¯¸ë””ì–´ í”Œë«í¼ê³¼ì˜ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•œ ì‚¬ìš©ì ê¸°ë°˜ í™•ëŒ€\",\n",
      "      \"AI ê¸°ìˆ  ë°œì „ìœ¼ë¡œ ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ê°€ëŠ¥ì„± (ì˜ˆ: ì‹¤ì‹œê°„ í¸ì§‘)\",\n",
      "      \"ê¸€ë¡œë²Œ ì‹œì¥ ì§„ì¶œì„ í†µí•œ ë§¤ì¶œ ë‹¤ê°í™” ê¸°íšŒ\",\n",
      "      \"ë¹„ë””ì˜¤ ë§ˆì¼€íŒ… ìˆ˜ìš” ì¦ê°€ë¡œ B2B ê³ ê° ìœ ì¹˜ ê°€ëŠ¥ì„±\"\n",
      "    ],\n",
      "    \"threats\": [\n",
      "      \"OpenAI Sora ì¶œì‹œ ì‹œ ê°€ê²© ê²½ìŸìœ¼ë¡œ ë§ˆì§„ 50% ì¶•ì†Œ ìœ„í—˜\",\n",
      "      \"ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ í’ˆì§ˆ í–¥ìƒìœ¼ë¡œ ë¬´ë£Œ ëŒ€ì²´ì¬ ì¦ê°€\",\n",
      "      \"ê¸°ìˆ  commoditizationìœ¼ë¡œ ì¸í•œ ê²½ìŸ ì‹¬í™”\",\n",
      "      \"ê·œì œ ë° ì €ì‘ê¶Œ ì´ìŠˆë¡œ ì¸í•œ ë²•ì  ë¦¬ìŠ¤í¬\",\n",
      "      \"ëŒ€ê¸°ì—…ì˜ ì‹œì¥ ì§„ì…ìœ¼ë¡œ ì¸í•œ ê°€ê²© ì••ë°•\",\n",
      "      \"ì†Œë¹„ì ì„ í˜¸ ë³€í™”ë¡œ ì¸í•œ ì‹œì¥ ìˆ˜ìš” ê°ì†Œ ê°€ëŠ¥ì„±\"\n",
      "    ]\n",
      "  },\n",
      "  \"generated_at\": \"2025-09-30T11:00:15.518364\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ (Runway ì˜ˆì‹œ)\n",
    "test_runway = {\n",
    "    \"company\": \"Runway\",\n",
    "    \"from_tech_summary\": {\n",
    "        \"company\": \"Runway\",\n",
    "        \"core_tech\": \"Text-to-video generation\",\n",
    "        \"strengths\": [\"ì˜ìƒ ìƒì„± AI\", \"í¬ë¦¬ì—ì´í„° UX\"],\n",
    "        \"weaknesses\": [\"GPU ë¹„ìš©\", \"ë°ì´í„° íˆ¬ëª…ì„±\"]\n",
    "    },\n",
    "    \"from_market\": {}\n",
    "}\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=json.dumps(test_runway, ensure_ascii=False))],\n",
    "    \"target_company\": \"\", \"target_tech\": {}, \"competitors\": [],\n",
    "    \"market_info\": {}, \"research_results\": {}, \"competitor_scores\": [], \"swot\": {}\n",
    "}\n",
    "\n",
    "# ì‹¤í–‰\n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(json.dumps(json.loads(final_state[\"messages\"][-1].content), indent=2, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-uj0hqo7A-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
